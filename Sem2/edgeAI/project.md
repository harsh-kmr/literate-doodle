# AI-Powered Multi-Class Pose Detection for Driver Behaviour Monitoring

## Introduction

This project implements an AI-powered system for multi-class pose detection to monitor driver behavior in real-time. It utilizes computer vision techniques to analyze driver poses, eye movements, hand positions, and head orientation to classify various driver states such as distracted driving, fatigue, or normal driving.

The system is designed for edge computing environments, making it suitable for deployment on resource-constrained devices like automotive systems or mobile platforms.

## Features

- Real-time Pose Detection using MediaPipe
- Multi-modal Feature Extraction: Eye tracking, Hand gesture recognition, Head pose estimation, Phone detection
- Driver State Classification
- Video Processing for live and recorded video
- Optimized for Edge Devices

## Installation

For installation and usage instructions, please refer to the GitHub repository.

## Usage

For running the project, custom model training, etc., please refer to the GitHub repository.

## Project Structure

For the full project structure and files, please refer to the GitHub repository.

## Team Members and Contributions

For team members and contributions, please refer to the GitHub repository.

## Links

- GitHub Repository: https://github.com/harsh-kmr/edge-ai-project/tree/main
- Demo Video: https://indianinstituteofscience-my.sharepoint.com/:f:/g/personal/harshkumar1_iisc_ac_in/Eo_0ujCKjClPmhYjkk5YbucBN1_mPig8EBLInQfk-A8XeA?e=dUtcjh
- Dataset: Not available for public use
- Model Files: https://github.com/harsh-kmr/edge-ai/blob/main/model.py

## License

This project is developed for academic purposes.

## Contact

For questions or contributions, please contact the team members or create an issue in the GitHub repository.
